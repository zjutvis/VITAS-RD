{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-24T10:53:43.452057Z",
     "start_time": "2025-03-24T10:53:16.099659Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def calculate_jaccard(set1, set2):\n",
    " \"\"\"Jaccard\"\"\"\n",
    " intersection = len(set1.intersection(set2))\n",
    " union = len(set1.union(set2))\n",
    " return intersection / union if union > 0 else 0\n",
    "\n",
    "\n",
    "def calculate_overlap(set1, set2):\n",
    " \"\"\": / \"\"\"\n",
    " intersection = len(set1.intersection(set2))\n",
    " denominator = min(len(set1), len(set2))\n",
    " return intersection / denominator if denominator > 0 else 0\n",
    "\n",
    "\n",
    "def calculate_modified_similarity(set1, set2, lambda_param=0.6):\n",
    " \"\"\", community\n",
    " Jaccard, Î»\"\"\"\n",
    " jaccard = calculate_jaccard(set1, set2)\n",
    " overlap1 = len(set1.intersection(set2)) / len(set1) if len(set1) > 0 else 0\n",
    " overlap2 = len(set1.intersection(set2)) / len(set2) if len(set2) > 0 else 0\n",
    "\n",
    " # ",
    " max_overlap = max(overlap1, overlap2)\n",
    "\n",
    " # ",
    " return lambda_param * jaccard + (1 - lambda_param) * max_overlap\n",
    "\n",
    "\n",
    "def load_community_data(date):\n",
    " \"\"\"communitydata\"\"\"\n",
    " file_path = f'../visualization/assets/data/{date}/handle/rank{date}.csv'\n",
    " if not os.path.exists(file_path):\n",
    " print(f\"fileexists: {file_path}\")\n",
    " return None\n",
    "\n",
    " df = pd.read_csv(file_path)\n",
    "\n",
    " # community {communityID: node}\n",
    " communities = {}\n",
    " for _, row in df.iterrows():\n",
    " comm_id = row['community']\n",
    " node_id = row['id']\n",
    "\n",
    " if comm_id not in communities:\n",
    " communities[comm_id] = set()\n",
    " communities[comm_id].add(node_id)\n",
    "\n",
    " return communities\n",
    "\n",
    "\n",
    "def analyze_community_events(t0_date, t1_date):\n",
    " \"\"\"timecommunity events\n",
    " process, community, event\"\"\"\n",
    " print(f\" {t0_date} {t1_date} community events\")\n",
    "\n",
    " # timecommunitydata\n",
    " t0_communities = load_community_data(t0_date)\n",
    " t1_communities = load_community_data(t1_date)\n",
    "\n",
    " if t0_communities is None or t1_communities is None:\n",
    " print(\"communitydata, skip\")\n",
    " return None\n",
    "\n",
    " # eventcommunity\n",
    " t0_assigned = set()\n",
    " t1_assigned = set()\n",
    "\n",
    " # event\n",
    " events = []\n",
    "\n",
    " # communitycommunitycommunity\n",
    " t0_large_communities = {cid: nodes for cid, nodes in t0_communities.items() if len(nodes) >= 3000}\n",
    " t0_small_communities = {cid: nodes for cid, nodes in t0_communities.items() if len(nodes) < 3000}\n",
    " t1_large_communities = {cid: nodes for cid, nodes in t1_communities.items() if len(nodes) >= 3000}\n",
    " t1_small_communities = {cid: nodes for cid, nodes in t1_communities.items() if len(nodes) < 3000}\n",
    "\n",
    " print(f\"t0community: {len(t0_large_communities)}, community: {len(t0_small_communities)}\")\n",
    " print(f\"t1community: {len(t1_large_communities)}, community: {len(t1_small_communities)}\")\n",
    "\n",
    " # 1: processcommunityevent ()\n",
    " for t0_comm_id, t0_nodes in sorted(t0_large_communities.items(), key=lambda x: len(x[1]), reverse=True):\n",
    " if t0_comm_id in t0_assigned:\n",
    " continue\n",
    "\n",
    " best_match = None\n",
    " best_similarity = 0\n",
    " for t1_comm_id, t1_nodes in sorted(t1_large_communities.items(), key=lambda x: len(x[1]), reverse=True):\n",
    " if t1_comm_id in t1_assigned:\n",
    " continue\n",
    "\n",
    " # ",
    " similarity = calculate_modified_similarity(t0_nodes, t1_nodes)\n",
    " if similarity > best_similarity:\n",
    " best_similarity = similarity\n",
    " best_match = (t1_comm_id, t1_nodes)\n",
    "\n",
    " # event\n",
    " if best_match and best_similarity >= 0.5:\n",
    " t1_comm_id, t1_nodes = best_match\n",
    "\n",
    " # ",
    " t0_size = len(t0_nodes)\n",
    " t1_size = len(t1_nodes)\n",
    " size_change_ratio = t1_size / t0_size if t0_size > 0 else float('inf')\n",
    "\n",
    " event_type = \"\"\n",
    " # ",
    " if size_change_ratio > 1.2: # 20%\n",
    " event_type = \"add\"\n",
    " elif size_change_ratio < 0.8: # 20%\n",
    " event_type = \"\"\n",
    "\n",
    " events.append({\n",
    " \"source_date\": t0_date,\n",
    " \"source_community\": t0_comm_id,\n",
    " \"target_date\": t1_date,\n",
    " \"target_community\": t1_comm_id,\n",
    " \"event_type\": event_type,\n",
    " \"similarity\": best_similarity,\n",
    " \"size_change_ratio\": size_change_ratio\n",
    " })\n",
    "\n",
    " t0_assigned.add(t0_comm_id)\n",
    " t1_assigned.add(t1_comm_id)\n",
    "\n",
    " # 2: processcommunityevent - ",
    " for t0_comm_id, t0_nodes in sorted(t0_large_communities.items(), key=lambda x: len(x[1]), reverse=True):\n",
    " if t0_comm_id in t0_assigned:\n",
    " continue\n",
    "\n",
    " # target(community)\n",
    " split_candidates = []\n",
    "\n",
    " # checkcommunity\n",
    " for t1_comm_id, t1_nodes in sorted(t1_large_communities.items(), key=lambda x: len(x[1]), reverse=True):\n",
    " if t1_comm_id in t1_assigned:\n",
    " continue\n",
    "\n",
    " overlap = len(t0_nodes.intersection(t1_nodes)) / len(t0_nodes)\n",
    " # 0.20.15\n",
    " if overlap >= 0.15:\n",
    " split_candidates.append((t1_comm_id, overlap, len(t1_nodes)))\n",
    "\n",
    " # checkcommunity\n",
    " for t1_comm_id, t1_nodes in sorted(t1_small_communities.items(), key=lambda x: len(x[1]), reverse=True):\n",
    " if t1_comm_id in t1_assigned:\n",
    " continue\n",
    "\n",
    " overlap = len(t0_nodes.intersection(t1_nodes)) / len(t0_nodes)\n",
    " # 0.10.05\n",
    " if overlap >= 0.05:\n",
    " split_candidates.append((t1_comm_id, overlap, len(t1_nodes)))\n",
    "\n",
    " # ",
    " split_candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    " # ",
    " if len(split_candidates) >= 1:\n",
    " cumulative_overlap = sum(overlap for _, overlap, _ in split_candidates)\n",
    "\n",
    " # , ",
    " if (len(split_candidates) >= 2 and cumulative_overlap >= 0.4) or \\\n",
    " (len(split_candidates) == 1 and cumulative_overlap >= 0.6):\n",
    " selected_targets = []\n",
    " selected_overlap = 0\n",
    "\n",
    " # condition\n",
    " for t1_comm_id, overlap, _ in split_candidates:\n",
    " if selected_overlap >= 0.7: # 0.80.7\n",
    " break\n",
    "\n",
    " selected_targets.append(t1_comm_id)\n",
    " selected_overlap += overlap\n",
    " t1_assigned.add(t1_comm_id)\n",
    "\n",
    " if selected_targets:\n",
    " events.append({\n",
    " \"source_date\": t0_date,\n",
    " \"source_community\": t0_comm_id,\n",
    " \"target_date\": t1_date,\n",
    " \"target_community\": selected_targets,\n",
    " \"event_type\": \"\",\n",
    " \"overlap_score\": selected_overlap\n",
    " })\n",
    " t0_assigned.add(t0_comm_id)\n",
    "\n",
    " # 3: processcommunityevent - ",
    " for t1_comm_id, t1_nodes in sorted(t1_large_communities.items(), key=lambda x: len(x[1]), reverse=True):\n",
    " if t1_comm_id in t1_assigned:\n",
    " continue\n",
    "\n",
    " # (community)\n",
    " merge_candidates = []\n",
    "\n",
    " # checkcommunity\n",
    " for t0_comm_id, t0_nodes in sorted(t0_large_communities.items(), key=lambda x: len(x[1]), reverse=True):\n",
    " if t0_comm_id in t0_assigned:\n",
    " continue\n",
    "\n",
    " overlap = len(t0_nodes.intersection(t1_nodes)) / len(t1_nodes)\n",
    " # 0.20.15\n",
    " if overlap >= 0.15:\n",
    " merge_candidates.append((t0_comm_id, overlap, len(t0_nodes)))\n",
    "\n",
    " # checkcommunity\n",
    " for t0_comm_id, t0_nodes in sorted(t0_small_communities.items(), key=lambda x: len(x[1]), reverse=True):\n",
    " if t0_comm_id in t0_assigned:\n",
    " continue\n",
    "\n",
    " overlap = len(t0_nodes.intersection(t1_nodes)) / len(t1_nodes)\n",
    " # 0.10.05\n",
    " if overlap >= 0.05:\n",
    " merge_candidates.append((t0_comm_id, overlap, len(t0_nodes)))\n",
    "\n",
    " # ",
    " merge_candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    " # ",
    " if len(merge_candidates) >= 1:\n",
    " cumulative_overlap = sum(overlap for _, overlap, _ in merge_candidates)\n",
    "\n",
    " # , ",
    " if (len(merge_candidates) >= 2 and cumulative_overlap >= 0.4) or \\\n",
    " (len(merge_candidates) == 1 and cumulative_overlap >= 0.6):\n",
    " selected_sources = []\n",
    " selected_overlap = 0\n",
    "\n",
    " # condition\n",
    " for t0_comm_id, overlap, _ in merge_candidates:\n",
    " if selected_overlap >= 0.7: # 0.80.7\n",
    " break\n",
    "\n",
    " selected_sources.append(t0_comm_id)\n",
    " selected_overlap += overlap\n",
    " t0_assigned.add(t0_comm_id)\n",
    "\n",
    " if selected_sources:\n",
    " events.append({\n",
    " \"source_date\": t0_date,\n",
    " \"source_community\": selected_sources,\n",
    " \"target_date\": t1_date,\n",
    " \"target_community\": t1_comm_id,\n",
    " \"event_type\": \"\",\n",
    " \"overlap_score\": selected_overlap\n",
    " })\n",
    " t1_assigned.add(t1_comm_id)\n",
    "\n",
    " # 4: processcommunityevent\n",
    " for t0_comm_id, t0_nodes in t0_large_communities.items():\n",
    " if t0_comm_id not in t0_assigned and len(t0_nodes) >= 100:\n",
    " events.append({\n",
    " \"source_date\": t0_date,\n",
    " \"source_community\": t0_comm_id,\n",
    " \"target_date\": t1_date,\n",
    " \"target_community\": None,\n",
    " \"event_type\": \"\",\n",
    " \"similarity\": 0\n",
    " })\n",
    " t0_assigned.add(t0_comm_id)\n",
    "\n",
    " for t1_comm_id, t1_nodes in t1_large_communities.items():\n",
    " if t1_comm_id not in t1_assigned and len(t1_nodes) >= 100:\n",
    " events.append({\n",
    " \"source_date\": t0_date,\n",
    " \"source_community\": None,\n",
    " \"target_date\": t1_date,\n",
    " \"target_community\": t1_comm_id,\n",
    " \"event_type\": \"\",\n",
    " \"similarity\": 0\n",
    " })\n",
    " t1_assigned.add(t1_comm_id)\n",
    "\n",
    " # 5: processcommunity events()\n",
    " # processcommunityevent\n",
    " for t0_comm_id, t0_nodes in sorted(t0_small_communities.items(), key=lambda x: len(x[1]), reverse=True):\n",
    " if t0_comm_id in t0_assigned:\n",
    " continue\n",
    "\n",
    " best_match = None\n",
    " best_overlap = 0\n",
    "\n",
    " for t1_comm_id, t1_nodes in sorted(t1_small_communities.items(), key=lambda x: len(x[1]), reverse=True):\n",
    " if t1_comm_id in t1_assigned:\n",
    " continue\n",
    "\n",
    " # processcommunity\n",
    " overlap = calculate_overlap(t0_nodes, t1_nodes)\n",
    " if overlap > best_overlap:\n",
    " best_overlap = overlap\n",
    " best_match = (t1_comm_id, t1_nodes)\n",
    "\n",
    " # addcommunityevent\n",
    " if best_match and best_overlap >= 0.5: # 0.60.5\n",
    " t1_comm_id, t1_nodes = best_match\n",
    "\n",
    " # ",
    " t0_size = len(t0_nodes)\n",
    " t1_size = len(t1_nodes)\n",
    " size_change_ratio = t1_size / t0_size if t0_size > 0 else float('inf')\n",
    "\n",
    " event_type = \"\"\n",
    " # ",
    " if size_change_ratio > 1.3: # community\n",
    " event_type = \"add\"\n",
    " elif size_change_ratio < 0.7:\n",
    " event_type = \"\"\n",
    "\n",
    " events.append({\n",
    " \"source_date\": t0_date,\n",
    " \"source_community\": t0_comm_id,\n",
    " \"target_date\": t1_date,\n",
    " \"target_community\": t1_comm_id,\n",
    " \"event_type\": event_type,\n",
    " \"similarity\": best_overlap,\n",
    " \"size_change_ratio\": size_change_ratio\n",
    " })\n",
    "\n",
    " t0_assigned.add(t0_comm_id)\n",
    " t1_assigned.add(t1_comm_id)\n",
    "\n",
    " # 6: processcommunityevent\n",
    " for t0_comm_id, t0_nodes in sorted(t0_small_communities.items(), key=lambda x: len(x[1]), reverse=True):\n",
    " if t0_comm_id in t0_assigned or len(t0_nodes) < 1: # community\n",
    " continue\n",
    "\n",
    " # target\n",
    " split_candidates = []\n",
    "\n",
    " for t1_comm_id, t1_nodes in sorted(t1_small_communities.items(), key=lambda x: len(x[1]), reverse=True):\n",
    " if t1_comm_id in t1_assigned:\n",
    " continue\n",
    "\n",
    " # ",
    " overlap = calculate_overlap(t0_nodes, t1_nodes)\n",
    " if overlap >= 0.3: # community\n",
    " split_candidates.append((t1_comm_id, overlap, len(t1_nodes)))\n",
    "\n",
    " # 2community\n",
    " if len(split_candidates) >= 2:\n",
    " cumulative_overlap = sum(overlap for _, overlap, _ in split_candidates)\n",
    "\n",
    " if cumulative_overlap >= 0.6: # community\n",
    " selected_targets = []\n",
    "\n",
    " for t1_comm_id, overlap, _ in split_candidates:\n",
    " selected_targets.append(t1_comm_id)\n",
    " t1_assigned.add(t1_comm_id)\n",
    "\n",
    " if selected_targets:\n",
    " events.append({\n",
    " \"source_date\": t0_date,\n",
    " \"source_community\": t0_comm_id,\n",
    " \"target_date\": t1_date,\n",
    " \"target_community\": selected_targets,\n",
    " \"event_type\": \"\",\n",
    " \"overlap_score\": cumulative_overlap\n",
    " })\n",
    " t0_assigned.add(t0_comm_id)\n",
    "\n",
    " # 7: processcommunityevent\n",
    " for t1_comm_id, t1_nodes in sorted(t1_small_communities.items(), key=lambda x: len(x[1]), reverse=True):\n",
    " if t1_comm_id in t1_assigned or len(t1_nodes) < 1: # community\n",
    " continue\n",
    "\n",
    " # ",
    " merge_candidates = []\n",
    "\n",
    " for t0_comm_id, t0_nodes in sorted(t0_small_communities.items(), key=lambda x: len(x[1]), reverse=True):\n",
    " if t0_comm_id in t0_assigned:\n",
    " continue\n",
    "\n",
    " # ",
    " overlap = calculate_overlap(t1_nodes, t0_nodes)\n",
    " if overlap >= 0.3: # community\n",
    " merge_candidates.append((t0_comm_id, overlap, len(t0_nodes)))\n",
    "\n",
    " # 2community\n",
    " if len(merge_candidates) >= 2:\n",
    " cumulative_overlap = sum(overlap for _, overlap, _ in merge_candidates)\n",
    "\n",
    " if cumulative_overlap >= 0.6: # community\n",
    " selected_sources = []\n",
    "\n",
    " for t0_comm_id, overlap, _ in merge_candidates:\n",
    " selected_sources.append(t0_comm_id)\n",
    " t0_assigned.add(t0_comm_id)\n",
    "\n",
    " if selected_sources:\n",
    " events.append({\n",
    " \"source_date\": t0_date,\n",
    " \"source_community\": selected_sources,\n",
    " \"target_date\": t1_date,\n",
    " \"target_community\": t1_comm_id,\n",
    " \"event_type\": \"\",\n",
    " \"overlap_score\": cumulative_overlap\n",
    " })\n",
    " t1_assigned.add(t1_comm_id)\n",
    "\n",
    " return events\n",
    "\n",
    "\n",
    "def generate_all_events():\n",
    " \"\"\"generatecommunity events\"\"\"\n",
    " all_events = []\n",
    " months = list(range(202401, 202411))\n",
    "\n",
    " for i in range(len(months) - 1):\n",
    " t0 = months[i]\n",
    " t1 = months[i + 1]\n",
    "\n",
    " events = analyze_community_events(t0, t1)\n",
    " if events:\n",
    " all_events.extend(events)\n",
    "\n",
    " # saveeventdata\n",
    " output_dir = '../visualization/assets/data/events'\n",
    " os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    " # JSONcolumnformatsave\n",
    " events_json = []\n",
    " for event in all_events:\n",
    " event_copy = event.copy()\n",
    " # column\n",
    " if isinstance(event_copy.get('source_community'), list) and len(event_copy['source_community']) > 0:\n",
    " if isinstance(event_copy['source_community'][0], set):\n",
    " event_copy['source_community'] = [list(comm) for comm in event_copy['source_community']]\n",
    " if isinstance(event_copy.get('target_community'), list) and len(event_copy['target_community']) > 0:\n",
    " if isinstance(event_copy['target_community'][0], set):\n",
    " event_copy['target_community'] = [list(comm) for comm in event_copy['target_community']]\n",
    " events_json.append(event_copy)\n",
    "\n",
    " with open(f'{output_dir}/community_events.json', 'w') as f:\n",
    " json.dump(events_json, f, indent=2)\n",
    "\n",
    " # generateCSVformat\n",
    " events_df = pd.DataFrame(all_events)\n",
    " events_df.to_csv(f'{output_dir}/community_events.csv', index=False)\n",
    "\n",
    " print(f\"generate {len(all_events)} community events\")\n",
    " return all_events\n",
    "\n",
    "\n",
    "# generateevent\n",
    "all_events = generate_all_events()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 202401 202402 community events\n",
      "t0community: 5, community: 16\n",
      "t1community: 4, community: 55\n",
      " 202402 202403 community events\n",
      "t0community: 4, community: 55\n",
      "t1community: 5, community: 16\n",
      " 202403 202404 community events\n",
      "t0community: 5, community: 16\n",
      "t1community: 5, community: 18\n",
      " 202404 202405 community events\n",
      "t0community: 5, community: 18\n",
      "t1community: 5, community: 22\n",
      " 202405 202406 community events\n",
      "t0community: 5, community: 22\n",
      "t1community: 4, community: 29\n",
      " 202406 202407 community events\n",
      "t0community: 4, community: 29\n",
      "t1community: 5, community: 25\n",
      " 202407 202408 community events\n",
      "t0community: 5, community: 25\n",
      "t1community: 5, community: 24\n",
      " 202408 202409 community events\n",
      "t0community: 5, community: 24\n",
      "t1community: 5, community: 19\n",
      " 202409 202410 community events\n",
      "t0community: 5, community: 19\n",
      "t1community: 6, community: 39\n",
      "generate 147 community events\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "75be5462a2362268"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}