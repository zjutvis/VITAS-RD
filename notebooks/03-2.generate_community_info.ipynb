{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-25T11:18:30.078133Z",
     "start_time": "2025-03-25T11:18:30.074694Z"
    }
   },
   "source": [
    "# ../visualization/assets/data/xxx/handle/relxxx.csv generate, maincreate_graph\n",
    "# createsuperNode dataframe, savenode\n",
    "# field: ",
    "# size: nodenode\n",
    "# community: nodecommunity\n",
    "# direct ratio: nodecommunitynodeidedgenodecone2000\n",
    "# p2p ratio: nodecommunitynodeidedgetypetype=0\n",
    "# influence: superNode.pynode_influence, community\n",
    "# structural entropy: ",
    "# superNodesave../visualization/assets/data/xxx/handle/superNode.csv\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T13:59:05.968546Z",
     "start_time": "2025-03-25T13:59:05.280275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from util.superNode import node_influence, log_normalize_cone"
   ],
   "id": "6daf4237d6882687",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T13:59:05.980596Z",
     "start_time": "2025-03-25T13:59:05.976303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_graph(rank, rel):\n",
    " \"\"\"\n",
    " create\n",
    " \"\"\"\n",
    " # create\n",
    " G = nx.DiGraph()\n",
    "\n",
    " for _, row in rank.iterrows():\n",
    " G.add_node(row['id'], pos=(row['x'], row['y']))\n",
    "\n",
    " for _, row in rel.iterrows():\n",
    " source = int(row['source'])\n",
    " target = int(row['target'])\n",
    " relation = int(row['relation'])\n",
    " if relation == -1:\n",
    " G.add_edge(source, target, weight=1)\n",
    " else:\n",
    " G.add_edge(source, target, weight=1)\n",
    " G.add_edge(target, source, weight=1)\n",
    " return G\n"
   ],
   "id": "b1abb69d1734bbc7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T13:59:06.120050Z",
     "start_time": "2025-03-25T13:59:06.111053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_community_metrics(date):\n",
    " \"\"\"\n",
    " communitygeneratesuperNodesuperLink\n",
    " \"\"\"\n",
    " print(f\"Processing date: {date}\")\n",
    "\n",
    " # readaddcommunity informationrankreldata\n",
    " rank_path = f'../visualization/assets/data/{date}/handle/rank{date}.csv'\n",
    " rel_path = f'../visualization/assets/data/{date}/rel{date}.csv'\n",
    " comm_rel_path = f'../visualization/assets/data/{date}/handle/rel{date}.csv'\n",
    "\n",
    " if not os.path.exists(rank_path) or not os.path.exists(rel_path):\n",
    " print(f\"Files for {date} not found. Skipping.\")\n",
    " return\n",
    "\n",
    " rank = pd.read_csv(rank_path)\n",
    " rel = pd.read_csv(rel_path)\n",
    " comm_rel = pd.read_csv(comm_rel_path)\n",
    "\n",
    " # create\n",
    " G = create_graph(rank, rel)\n",
    "\n",
    " # createcommunitynodeIDmapping\n",
    " community_nodes = {}\n",
    " for _, row in rank.iterrows():\n",
    " if row['community'] not in community_nodes:\n",
    " community_nodes[row['community']] = []\n",
    " community_nodes[row['community']].append(row['id'])\n",
    "\n",
    " # createsuperNode DataFrame, community(node)\n",
    " superNode = rank.groupby('community').size().reset_index(name='size')\n",
    "\n",
    " # direct ratio - communitycone>2000nodeedge\n",
    " direct_ratio = {}\n",
    " for community, nodes in community_nodes.items():\n",
    " # communitynodeedge\n",
    " community_edges = rel[(rel['source'].isin(nodes)) | (rel['target'].isin(nodes))]\n",
    "\n",
    " # cone > 2000node\n",
    " high_cone_nodes = set(rank[rank['cone'] > 2000]['id'].tolist())\n",
    "\n",
    " # conenodeedge\n",
    " high_cone_edges = community_edges[\n",
    " (community_edges['source'].isin(high_cone_nodes)) |\n",
    " (community_edges['target'].isin(high_cone_nodes))\n",
    " ]\n",
    "\n",
    " # ",
    " total_edges = len(community_edges)\n",
    " direct_ratio[community] = len(high_cone_edges) / total_edges if total_edges > 0 else 0\n",
    "\n",
    " superNode['direct_ratio'] = superNode['community'].map(direct_ratio)\n",
    "\n",
    " # p2p ratio - relationtype0edge\n",
    " p2p_ratio = {}\n",
    " for community, nodes in community_nodes.items():\n",
    " # communitynodeedge\n",
    " community_edges = rel[(rel['source'].isin(nodes)) | (rel['target'].isin(nodes))]\n",
    "\n",
    " # relation=0edge\n",
    " p2p_edges = community_edges[community_edges['relation'] == 0]\n",
    "\n",
    " # ",
    " total_edges = len(community_edges)\n",
    " p2p_ratio[community] = len(p2p_edges) / total_edges if total_edges > 0 else 0\n",
    "\n",
    " superNode['p2p_ratio'] = superNode['community'].map(p2p_ratio)\n",
    "\n",
    " # influence\n",
    " superNode = node_influence(G, rank, superNode)\n",
    " ",
    " # addstructural_entropy\n",
    " # superNode['structural_entropy'] = np.nan\n",
    " ",
    " # save\n",
    " os.makedirs(f'../visualization/assets/data/{date}/handle', exist_ok=True)\n",
    " superNode.to_csv(f'../visualization/assets/data/{date}/handle/superNode.csv', index=False)\n",
    " ",
    " # savesuperLink\n",
    " calculate_super_links(date, comm_rel)\n",
    " ",
    " print(f\"Completed processing for {date}\")\n",
    " return superNode\n",
    "\n",
    "def calculate_super_links(date, rel):\n",
    " \"\"\"\n",
    " communitygeneratesuperLink\n",
    " \"\"\"\n",
    " if 'type' not in rel.columns:\n",
    " print(f\"'type' column not found in rel for {date}. Skipping superLink generation.\")\n",
    " return\n",
    " ",
    " # filtercommunityedge\n",
    " cross_community_edges = rel[rel['type'].astype(str).str.contains('-')]\n",
    " ",
    " # community\n",
    " superLink_counts = {}\n",
    " for _, row in cross_community_edges.iterrows():\n",
    " type_str = str(row['type'])\n",
    " if '-' in type_str:\n",
    " source, target = map(int, type_str.split('-'))\n",
    " link_key = (source, target)\n",
    " superLink_counts[link_key] = superLink_counts.get(link_key, 0) + 1\n",
    " ",
    " # createsuperLink DataFrame\n",
    " superLink_data = []\n",
    " for (source, target), count in superLink_counts.items():\n",
    " superLink_data.append({\n",
    " 'source': source,\n",
    " 'target': target,\n",
    " 'count': count\n",
    " })\n",
    " ",
    " superLink = pd.DataFrame(superLink_data)\n",
    " ",
    " # save\n",
    " superLink.to_csv(f'../visualization/assets/data/{date}/handle/superLink.csv', index=False)\n"
   ],
   "id": "72cbe65f8272485e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T14:03:41.124755Z",
     "start_time": "2025-03-25T13:59:06.619746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Process data from 202401 to 202410\n",
    "for date in range(202401, 202411):\n",
    " try:\n",
    " superNode = calculate_community_metrics(date)\n",
    " print(f\"Successfully processed {date}\")\n",
    " except Exception as e:\n",
    " print(f\"Error processing {date}: {e}\")\n"
   ],
   "id": "5fbae94452304d36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing date: 202401\n",
      "Completed processing for 202401\n",
      "Successfully processed 202401\n",
      "Processing date: 202402\n",
      "Completed processing for 202402\n",
      "Successfully processed 202402\n",
      "Processing date: 202403\n",
      "Completed processing for 202403\n",
      "Successfully processed 202403\n",
      "Processing date: 202404\n",
      "Completed processing for 202404\n",
      "Successfully processed 202404\n",
      "Processing date: 202405\n",
      "Completed processing for 202405\n",
      "Successfully processed 202405\n",
      "Processing date: 202406\n",
      "Completed processing for 202406\n",
      "Successfully processed 202406\n",
      "Processing date: 202407\n",
      "Completed processing for 202407\n",
      "Successfully processed 202407\n",
      "Processing date: 202408\n",
      "Completed processing for 202408\n",
      "Successfully processed 202408\n",
      "Processing date: 202409\n",
      "Completed processing for 202409\n",
      "Successfully processed 202409\n",
      "Processing date: 202410\n",
      "Completed processing for 202410\n",
      "Successfully processed 202410\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T14:03:41.162941Z",
     "start_time": "2025-03-25T14:03:41.158945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ../visualization/assets/data/xxx/handle/relxxx.csvprocess\n",
    "# type-, communityedge, communityedge\n",
    "# createsuperLink dataframe, savecommunity\n",
    "# field: source, target, count\n",
    "# source, targetcommunity, countcommunityrelxxx.csvtypefield\n",
    "# superLinksave../visualization/assets/data/xxx/handle/superLink.csv\n",
    "# : calculate_community_metrics\n"
   ],
   "id": "5b8b984ecdd519ef",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T14:03:41.199170Z",
     "start_time": "2025-03-25T14:03:41.196616Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ae0fa73d4a734291",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T14:16:44.817205Z",
     "start_time": "2025-03-25T14:16:44.806609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# readsuperLink, sourcetarget, edgeweightcountfield\n",
    "# nodesrich-club, clustering coefficient, betweenness centrality, tier1, tier2(tier1communitycone2000node/), tier2communitycone1000, 2000node/\n",
    "# fieldaddsuperNode, save../visualization/assets/data/xxx/handle/superNode.csv\n",
    "\n",
    "def calculate_additional_metrics(date):\n",
    " \"\"\"\n",
    " communityaddsuperNode\n",
    " \"\"\"\n",
    " print(f\"Calculating additional metrics for {date}\")\n",
    " ",
    " # filepath\n",
    " superNode_path = f'../visualization/assets/data/{date}/handle/superNode.csv'\n",
    " superLink_path = f'../visualization/assets/data/{date}/handle/superLink.csv'\n",
    " rank_path = f'../visualization/assets/data/{date}/handle/rank{date}.csv'\n",
    " ",
    " # Check if files exist\n",
    " if not all(os.path.exists(p) for p in [superNode_path, superLink_path, rank_path]):\n",
    " print(f\"Required files for {date} not found. Skipping.\")\n",
    " return\n",
    " ",
    " # readfile\n",
    " superNode = pd.read_csv(superNode_path)\n",
    " superLink = pd.read_csv(superLink_path)\n",
    " rank = pd.read_csv(rank_path)\n",
    " ",
    " # createcommunity\n",
    " G_comm = nx.DiGraph()\n",
    " ",
    " # addnode\n",
    " for _, row in superNode.iterrows():\n",
    " G_comm.add_node(row['community'])\n",
    " ",
    " # addedge\n",
    " for _, row in superLink.iterrows():\n",
    " G_comm.add_edge(row['source'], row['target'], weight=row['count'])\n",
    " ",
    " # , ",
    " if len(G_comm.nodes) == 0:\n",
    " print(f\"No communities found for {date}. Skipping.\")\n",
    " return superNode\n",
    " ",
    " # rich club coefficient\n",
    " # nodes, node>=nodenodeedgeedge\n",
    " rich_club = {}\n",
    " nodes = list(G_comm.nodes())\n",
    " for node in nodes:\n",
    " node_degree = G_comm.degree(node)\n",
    " higher_degree_nodes = [n for n in nodes if G_comm.degree(n) >= node_degree]\n",
    " ",
    " if len(higher_degree_nodes) <= 1: # >=nodenode\n",
    " rich_club[node] = 0\n",
    " continue\n",
    " ",
    " possible_edges = len(higher_degree_nodes) * (len(higher_degree_nodes) - 1)\n",
    " actual_edges = sum(1 for u in higher_degree_nodes for v in higher_degree_nodes ",
    " if u != v and G_comm.has_edge(u, v))\n",
    " ",
    " rich_club[node] = actual_edges / possible_edges if possible_edges > 0 else 0\n",
    " ",
    " # ",
    " clustering = nx.clustering(G_comm.to_undirected())\n",
    " ",
    " # ",
    " betweenness = nx.betweenness_centrality(G_comm)\n",
    " ",
    " # createcommunitynodeIDmapping\n",
    " community_nodes = {}\n",
    " for _, row in rank.iterrows():\n",
    " if row['community'] not in community_nodes:\n",
    " community_nodes[row['community']] = []\n",
    " community_nodes[row['community']].append(row['id'])\n",
    " ",
    " # tier1tier2\n",
    " tier1_ratio = {}\n",
    " tier2_ratio = {}\n",
    " ",
    " # () - community\n",
    " organization = {}\n",
    " ",
    " for community, nodes in community_nodes.items():\n",
    " # communitynode\n",
    " nodes_in_comm = rank[rank['id'].isin(nodes)]\n",
    " total_nodes = len(nodes_in_comm)\n",
    " ",
    " if total_nodes == 0:\n",
    " tier1_ratio[community] = 0\n",
    " tier2_ratio[community] = 0\n",
    " organization[community] = \"Unknown\"\n",
    " continue\n",
    " ",
    " # Tier1: cone > 2000\n",
    " tier1_nodes = nodes_in_comm[nodes_in_comm['cone'] > 2000]\n",
    " tier1_ratio[community] = len(tier1_nodes) / total_nodes\n",
    " ",
    " # Tier2: 1000 < cone <= 2000\n",
    " tier2_nodes = nodes_in_comm[(nodes_in_comm['cone'] > 1000) & (nodes_in_comm['cone'] <= 2000)]\n",
    " tier2_ratio[community] = len(tier2_nodes) / total_nodes\n",
    " ",
    " # ",
    " if 'source' in nodes_in_comm.columns:\n",
    " country_counts = nodes_in_comm['source'].value_counts()\n",
    " if not country_counts.empty:\n",
    " most_common_country = country_counts.index[0]\n",
    " organization[community] = most_common_country\n",
    " else:\n",
    " organization[community] = \"Unknown\"\n",
    " else:\n",
    " organization[community] = \"Unknown\"\n",
    " ",
    " # superNode DataFrame\n",
    " superNode['rich_club'] = superNode['community'].map(rich_club)\n",
    " superNode['clustering'] = superNode['community'].map(clustering)\n",
    " superNode['betweenness'] = superNode['community'].map(betweenness)\n",
    " superNode['tier1_ratio'] = superNode['community'].map(tier1_ratio)\n",
    " superNode['tier2_ratio'] = superNode['community'].map(tier2_ratio)\n",
    " superNode['organization'] = superNode['community'].map(organization)\n",
    " ",
    " # savesuperNode\n",
    " superNode.to_csv(superNode_path, index=False)\n",
    " print(f\"Additional metrics calculated and saved for {date}\")\n",
    " ",
    " return superNode\n"
   ],
   "id": "d085dee2afcdb804",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T14:17:03.366962Z",
     "start_time": "2025-03-25T14:16:45.687953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Process data from 202401 to 202410, ",
    "for date in range(202401, 202411):\n",
    " try:\n",
    " updated_superNode = calculate_additional_metrics(date)\n",
    " print(f\"Successfully processed additional metrics for {date}\")\n",
    " except Exception as e:\n",
    " print(f\"Error processing additional metrics for {date}: {e}\")\n",
    "\n"
   ],
   "id": "e8f1a3e605c426be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating additional metrics for 202401\n",
      "Additional metrics calculated and saved for 202401\n",
      "Successfully processed additional metrics for 202401\n",
      "Calculating additional metrics for 202402\n",
      "Additional metrics calculated and saved for 202402\n",
      "Successfully processed additional metrics for 202402\n",
      "Calculating additional metrics for 202403\n",
      "Additional metrics calculated and saved for 202403\n",
      "Successfully processed additional metrics for 202403\n",
      "Calculating additional metrics for 202404\n",
      "Additional metrics calculated and saved for 202404\n",
      "Successfully processed additional metrics for 202404\n",
      "Calculating additional metrics for 202405\n",
      "Additional metrics calculated and saved for 202405\n",
      "Successfully processed additional metrics for 202405\n",
      "Calculating additional metrics for 202406\n",
      "Additional metrics calculated and saved for 202406\n",
      "Successfully processed additional metrics for 202406\n",
      "Calculating additional metrics for 202407\n",
      "Additional metrics calculated and saved for 202407\n",
      "Successfully processed additional metrics for 202407\n",
      "Calculating additional metrics for 202408\n",
      "Additional metrics calculated and saved for 202408\n",
      "Successfully processed additional metrics for 202408\n",
      "Calculating additional metrics for 202409\n",
      "Additional metrics calculated and saved for 202409\n",
      "Successfully processed additional metrics for 202409\n",
      "Calculating additional metrics for 202410\n",
      "Additional metrics calculated and saved for 202410\n",
      "Successfully processed additional metrics for 202410\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "266351f8bfcc6fe6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}