{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:53:47.319671Z",
     "start_time": "2025-03-24T10:53:46.985955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# readCSVfile\n",
    "def process_community_data():\n",
    " # readeventdata\n",
    " events_df = pd.read_csv('../visualization/assets/data/events/community_events.csv')\n",
    "\n",
    " # read202401communitydata\n",
    " supernode_path = '../visualization/assets/data/202401/handle/superNode.csv'\n",
    " try:\n",
    " supernode_df = pd.read_csv(supernode_path)\n",
    " print(f\"successreadsuperNode.csv, column name: {supernode_df.columns.tolist()}\")\n",
    " except Exception as e:\n",
    " print(f\"readsuperNode.csverror occurred: {e}\")\n",
    " # fileexists, createDataFrame\n",
    " supernode_df = pd.DataFrame()\n",
    "\n",
    " # time\n",
    " time_slices = sorted(list(set(events_df['source_date'].unique()) | set(events_df['target_date'].unique())))\n",
    " # timePythoninttype, JSONcolumn\n",
    " time_slices = [int(t) for t in time_slices if not pd.isna(t)]\n",
    " ",
    " # processnodedata, community\n",
    " community_sizes = {}\n",
    " if not supernode_df.empty:\n",
    " # attemptcommunityIDcolumn\n",
    " community_col = None\n",
    " size_col = None\n",
    "\n",
    " # checkcolumn name\n",
    " for possible_col in ['community', 'community_id', 'id']:\n",
    " if possible_col in supernode_df.columns:\n",
    " community_col = possible_col\n",
    " break\n",
    "\n",
    " for possible_col in ['size', 'count', 'node_count']:\n",
    " if possible_col in supernode_df.columns:\n",
    " size_col = possible_col\n",
    " break\n",
    "\n",
    " # column, ",
    " if community_col is None and len(supernode_df.columns) > 0:\n",
    " community_col = supernode_df.columns[0]\n",
    "\n",
    " if size_col is None and len(supernode_df.columns) > 1:\n",
    " size_col = supernode_df.columns[1]\n",
    "\n",
    " # mappingcommunityID\n",
    " if community_col and size_col:\n",
    " for _, row in supernode_df.iterrows():\n",
    " community_id = row[community_col]\n",
    " size = row[size_col]\n",
    " community_sizes[int(community_id) if isinstance(community_id, (np.integer, float, int)) else community_id] = int(size) if isinstance(size, (np.integer, float, int)) else size\n",
    " else:\n",
    " print(\": superNode.csvcommunitycolumn\")\n",
    " ",
    " # 202401community\n",
    " initial_communities = []\n",
    " for _, row in events_df.iterrows():\n",
    " if row['source_date'] == 202401 and row['source_community'] != \"\":\n",
    " if not pd.isna(row['source_community']):\n",
    " try:\n",
    " # processcolumn \"[8, 35]\"\n",
    " if isinstance(row['source_community'], str) and '[' in row['source_community']:\n",
    " # columncommunityID\n",
    " comm_list = eval(row['source_community'])\n",
    " for comm_id in comm_list:\n",
    " if comm_id not in initial_communities:\n",
    " initial_communities.append(comm_id)\n",
    " else:\n",
    " comm_id = int(float(row['source_community']))\n",
    " if comm_id not in initial_communities:\n",
    " initial_communities.append(comm_id)\n",
    " except:\n",
    " # skipcommunityID\n",
    " pass\n",
    " ",
    " # event\n",
    " merge_split_communities = set()\n",
    " for _, row in events_df.iterrows():\n",
    " event_type = row['event_type']\n",
    " if event_type == '' or event_type == '':\n",
    " # processcommunity\n",
    " if not pd.isna(row['source_community']) and row['source_community'] != \"\":\n",
    " if isinstance(row['source_community'], str) and '[' in row['source_community']:\n",
    " comm_list = eval(row['source_community'])\n",
    " for comm_id in comm_list:\n",
    " merge_split_communities.add(comm_id)\n",
    " else:\n",
    " try:\n",
    " comm_id = int(float(row['source_community']))\n",
    " merge_split_communities.add(comm_id)\n",
    " except:\n",
    " pass\n",
    " ",
    " # processtargetcommunity\n",
    " if not pd.isna(row['target_community']) and row['target_community'] != \"\":\n",
    " if isinstance(row['target_community'], str) and '[' in row['target_community']:\n",
    " comm_list = eval(row['target_community'])\n",
    " for comm_id in comm_list:\n",
    " merge_split_communities.add(comm_id)\n",
    " else:\n",
    " try:\n",
    " comm_id = int(float(row['target_community']))\n",
    " merge_split_communities.add(comm_id)\n",
    " except:\n",
    " pass\n",
    " ",
    " # community\n",
    " community_scores = []\n",
    " for comm_id in initial_communities:\n",
    " size = community_sizes.get(comm_id, 0) # 0\n",
    " is_merge_split = comm_id in merge_split_communities\n",
    " ",
    " # communityID, /eventaddcolumn\n",
    " community_scores.append((comm_id, size, is_merge_split))\n",
    " ",
    " # /event, ",
    " sorted_communities = sorted(community_scores, key=lambda x: (not x[2], -x[1]))\n",
    " ",
    " # 15community()\n",
    " top_communities = sorted_communities[:min(15, len(sorted_communities))]\n",
    " top_community_ids = [int(comm[0]) for comm in top_communities]\n",
    "\n",
    " ",
    "\n",
    " ",
    " # createJSONoutput\n",
    " result = {\n",
    " \"timeSlices\": time_slices,\n",
    " \"initialCommunities\": top_community_ids,\n",
    " }\n",
    " ",
    "\n",
    " ",
    " # JSONfile\n",
    " with open('community_evolution.json', 'w', encoding='utf-8') as f:\n",
    " json.dump(result, f, ensure_ascii=False, indent=2)\n",
    " ",
    " print(\"dataprocesssuccess.outputcommunity_evolution.json\")\n",
    " print(f\"community: {len(top_community_ids)}\")\n",
    " return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    " process_community_data()\n"
   ],
   "id": "569b06856bbb3c93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successreadsuperNode.csv, column name: ['community', 'size', 'direct_ratio', 'p2p_ratio', 'influence', 'log_influence', 'radius', 'structural_entropy']\n",
      "dataprocesssuccess.outputcommunity_evolution.json\n",
      "community: 15\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:53:47.343796Z",
     "start_time": "2025-03-24T10:53:47.340920Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "87752fa288f1bcc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:53:47.442304Z",
     "start_time": "2025-03-24T10:53:47.439175Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cd6276ff4195e5ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:53:47.459853Z",
     "start_time": "2025-03-24T10:53:47.456778Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d5659c9ddea642b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:53:47.588338Z",
     "start_time": "2025-03-24T10:53:47.495763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# readvisualization/assets/data/events/community_events.json visualization/assets/data/events/community_events.csv\n",
    "# jsontimerange, ��\n",
    "# community, community_events.csv, source_communitysource_date, targetcommunity, , time, .\n",
    "# community, , , existscommunity, community.: 01acommunity, 02bc, 03bc\n",
    "# 01: a,[b,c],[d,e],[,f],[]...\n",
    "# exists\n",
    "# exportcsv, time, communitycommunity\n",
    "\n",
    "def track_community_evolution():\n",
    " # readeventdata\n",
    " events_df = pd.read_csv('../visualization/assets/data/events/community_events.csv')\n",
    " ",
    " # readgenerateJSONdata\n",
    " try:\n",
    " with open('community_evolution.json', 'r', encoding='utf-8') as f:\n",
    " data = json.load(f)\n",
    " time_slices = data['timeSlices']\n",
    " initial_communities = data['initialCommunities']\n",
    " except (FileNotFoundError, KeyError):\n",
    " # ���fileexists, process\n",
    " data = process_community_data()\n",
    " time_slices = data['timeSlices']\n",
    " initial_communities = data['initialCommunities']\n",
    " ",
    " print(f\" {len(initial_communities)} community {len(time_slices)} time\")\n",
    " ",
    " # creatematrix\n",
    " # : community\n",
    " # column: time\n",
    " evolution_matrix = []\n",
    " ",
    " # addtime\n",
    " evolution_matrix.append(time_slices)\n",
    " ",
    " # define, community\n",
    " def track_community(comm_id, current_time_idx, target_communities=None):\n",
    " \"\"\"\n",
    " community\n",
    " ",
    " :\n",
    " comm_id - communityID\n",
    " current_time_idx - time\n",
    " target_communities - timecommunityID()\n",
    " ",
    " :\n",
    " column, communitytime\n",
    " \"\"\"\n",
    " if target_communities is None:\n",
    " target_communities = [[] for _ in range(len(time_slices))]\n",
    " ",
    " # time, ",
    " if current_time_idx >= len(time_slices) - 1:\n",
    " return target_communities\n",
    " ",
    " current_time = time_slices[current_time_idx]\n",
    " next_time = time_slices[current_time_idx + 1]\n",
    " ",
    " # communitytimeevent\n",
    " events = events_df[(events_df['source_date'] == current_time) & ",
    " (events_df['target_date'] == next_time)]\n",
    " ",
    " # communityevent\n",
    " related_event = None\n",
    " for _, event in events.iterrows():\n",
    " source_comm = event['source_community']\n",
    " # processcolumn\n",
    " if isinstance(source_comm, str) and '[' in source_comm:\n",
    " try:\n",
    " source_comm_list = eval(source_comm)\n",
    " if comm_id in source_comm_list:\n",
    " related_event = event\n",
    " break\n",
    " except:\n",
    " pass\n",
    " else:\n",
    " try:\n",
    " if int(float(source_comm)) == comm_id:\n",
    " related_event = event\n",
    " break\n",
    " except:\n",
    " pass\n",
    " ",
    " if related_event is None:\n",
    " # event, communitydata\n",
    " return target_communities\n",
    " ",
    " event_type = related_event['event_type']\n",
    " target_comm = related_event['target_community']\n",
    " ",
    " if event_type == '':\n",
    " # community, ",
    " return target_communities\n",
    " ",
    " if pd.isna(target_comm) or target_comm == \"\":\n",
    " # targetcommunity, ",
    " return target_communities\n",
    " ",
    " if event_type == '':\n",
    " # processevent, community\n",
    " try:\n",
    " target_comm_list = eval(target_comm) if isinstance(target_comm, str) and '[' in target_comm else [int(float(target_comm))]\n",
    " target_communities[current_time_idx + 1].extend(target_comm_list)\n",
    " ",
    " # community\n",
    " for split_comm in target_comm_list:\n",
    " track_community(split_comm, current_time_idx + 1, target_communities)\n",
    " except:\n",
    " print(f\"processeventerror occurred: {target_comm}\")\n",
    " ",
    " elif event_type == '':\n",
    " # processevent, targetcommunity\n",
    " try:\n",
    " if isinstance(target_comm, str) and '[' in target_comm:\n",
    " target_comm_list = eval(target_comm)\n",
    " target_communities[current_time_idx + 1].extend(target_comm_list)\n",
    " # community, ",
    " if target_comm_list:\n",
    " track_community(target_comm_list[0], current_time_idx + 1, target_communities)\n",
    " else:\n",
    " target_comm_id = int(float(target_comm))\n",
    " target_communities[current_time_idx + 1].append(target_comm_id)\n",
    " track_community(target_comm_id, current_time_idx + 1, target_communities)\n",
    " except:\n",
    " print(f\"processeventerror occurred: {target_comm}\")\n",
    " else:\n",
    " # eventtype(, add, )\n",
    " try:\n",
    " target_comm_id = int(float(target_comm))\n",
    " target_communities[current_time_idx + 1].append(target_comm_id)\n",
    " track_community(target_comm_id, current_time_idx + 1, target_communities)\n",
    " except:\n",
    " print(f\"processeventerror occurred: {target_comm}\")\n",
    " ",
    " return target_communities\n",
    " ",
    " # community\n",
    " for comm_id in initial_communities:\n",
    " # timecommunitycolumn\n",
    " community_evolution = [[] for _ in range(len(time_slices))]\n",
    " # community\n",
    " community_evolution[0] = [comm_id]\n",
    " ",
    " # community\n",
    " community_evolution = track_community(comm_id, 0, community_evolution)\n",
    " ",
    " # timeformatcommunityID\n",
    " formatted_evolution = []\n",
    " for time_idx, communities in enumerate(community_evolution):\n",
    " if not communities:\n",
    " formatted_evolution.append(\"\") # columncommunitydata\n",
    " elif len(communities) == 1:\n",
    " formatted_evolution.append(str(communities[0])) # community\n",
    " else:\n",
    " # communityID\n",
    " unique_communities = sorted(list(set(communities)))\n",
    " formatted_evolution.append(str(unique_communities)) # community()\n",
    " ",
    " evolution_matrix.append(formatted_evolution)\n",
    " ",
    " # CSVfile\n",
    " df = pd.DataFrame(evolution_matrix)\n",
    " df.to_csv('community_evolution_matrix.csv', index=False, header=False)\n",
    " print(f\"communitymatrix community_evolution_matrix.csv\")\n",
    " ",
    " return evolution_matrix\n",
    "\n",
    "# ",
    "if __name__ == \"__main__\":\n",
    " evolution_matrix = track_community_evolution()\n",
    "\n"
   ],
   "id": "775e1475b5ab50c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15 community 10 time\n",
      "communitymatrix community_evolution_matrix.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:53:47.602985Z",
     "start_time": "2025-03-24T10:53:47.600280Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7e8cd6107f277a83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:53:47.611977Z",
     "start_time": "2025-03-24T10:53:47.609877Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e99aa3c6dbf8da7f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}